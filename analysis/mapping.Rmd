---
title: "mapping "
author:  "Mofi Islam and Dennis Wollersheim "
date: "2018-04-30"
output:
  workflowr::wflow_html:
    toc: false
--- 
```{r pre_initial, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

rm(list=ls())
options(width = 200)
show_code = FALSE
source("lib/functions.R")
source("lib/standardisation.R")
source("lib/get_data.R")
source("lib/generate_data_frames.R")
source("lib/mapping_functions.R")
source("lib/mapping_paper.R")
library('tidyverse')
opts_chunk$set(echo = FALSE)
states=1:9

```


```{r initial, results='hide', message=FALSE, warning=FALSE}

dataset="_rr"
dataset=""

get_data_from_cache(dataset = dataset)


#source('lib/findOverlap_simplified.R')

tic( 'reading dta')
foreign::read.dta( 'data/nobackup/match_multiyear.v2.dta' ) %>%
  as.tibble() %>% 
  { . } -> df_match
toc()



supply_year.=2014
LGA_dd_frequency <- function( df_match., supply_year. ) {

  df_population %>%
    group_by( lga ) %>%
    filter( supply_year==supply_year.) %>%
    summarise( population=sum( population )) %>% 
    { . } -> df_population.


  df_match. %>%
    filter( ndays >0 ) %>%
    filter( lga != '.' & lga != '99399' ) %>%
    filter( supply_year==supply_year.)  %>%
    distinct( pin, lga ) %>% 
    count( lga ) %>% 
    inner_join ( df_population. ) %>% 
    mutate( rate = n/population*10000) 

}



#I took the matches, counted the number of distinct patients per year, merged in overall oz population, and X 10000 to get pp/1000 population

df_match %>%
  filter( ndays >0 ) %>%
  distinct( supply_year, pin ) %>%
  count( supply_year ) %>%
  f_join_population( 'supply_year') %>%
  mutate ( rate = n / population * 10000 ) %>%
  xc()


  r
  df_population %>%
    filter( supply_year==supply_year.) %>%
    summarise( population=sum( population )) %>% 
    { . } -> df_population.


  df_match %>%
    filter( ndays >0 ) %>%
    filter( supply_year==supply_year.)  %>%
    distinct( pin ) %>% 
    count( ) %>% 
    inner_join ( df_population., by='1' ) %>% 
    mutate( rate = n/population*10000) 

}

df_match %>%
  Aus_dd_frequency()


########################################
########################################
# standardise by year, average / year , population / year 

# find individual year
lga_dd_frequency_standardised<- function( df_match., 
                                     supply_year. = df_match. %>% distinct( supply_year ) %$% supply_year
                                     ) {

  df_match. %>%
    filter( ndays >0 ) %>%
    filter( lga != '.' & lga != '99399' ) %>%
    distinct( age, sex, pin, lga) %>%
    count( lga, age, sex ) %>%
    simple_standardise_value( group_by_vars=qc(lga) ,  
                             count_var='n' ,
                             df_population. = filter( df_population, supply_year==supply_year.)
                             ) %>%
    mutate( rate = rate * 10 ) %>%
    right_join( df_population %>% distinct( lga ) , by='lga') %>%
    mutate( rate = ifelse( is.na( rate), 0, rate ))

}

df_match %>%
  group_by( supply_year)  %>%
  do( year_freq = lga_dd_frequency_standardised( . ) ) %>%
  unnest( year_freq )  %>%
  group_by( lga ) %>%
  summarise( rate = mean( rate) ) %>%
  ungroup() %>%
  mutate( value = cut( rate, 
                        breaks=quantile( rate, probs=seq(0,1,1/3) ), 
                        labels=qc( low, medium, high ))) %>%
     mutate( value = factor( ifelse( is.na( value ), 1, value ),
                            labels=qc( low, medium, high )
                            )) %>% 
     { . } -> df_map 

########################################
########################################

#df_match. = df_match  %>% filter( supply_year=='2014')

# send mofi per year matches as well
# figure make font bigger for legend

# 10year dataset in cloudstor
# prediciton variables

if (FALSE) {   # v1;  all 4 years
  df_match %>%
    filter( ndays >0 ) %>%
    filter( lga != '.' & lga != '99399' ) %>%
    distinct( age, sex, pin, lga) %>%
    count( lga, age, sex ) %>%
    simple_standardise_value( group_by_vars=qc(lga) ,  
                            count_var='n' ,
                            df_population. = filter( df_population, supply_year=='2013')
                            ) %>%
    mutate( rate = rate * 10 ) %>%
    right_join( df_population %>% distinct( lga ) ) %>%
    mutate( rate = ifelse( is.na( rate), 0, rate ),
          value = cut( rate, 
                        breaks=quantile( rate, probs=seq(0,1,1/3) ), 
                        labels=qc( low, medium, high ))) %>%
    mutate( value = factor( ifelse( is.na( value ), 1, value ),
                          labels=qc( low, medium, high )
    )) %>% 
  { . } -> df_map 
}

print_map( df_map, title="Adjusted density\nof concurrent users", filename='/tmp/double_dipping_level.png', inset_states=c(1,2,4:6 ) ) -> a



# What is your year-wise overall double dipper for Australia? (unstandardized)




# Also can you please send me the highest double-dipper number for any individual year (after standardization)?

```{r test_mapping_all_years  }


df_map  %>% 
  group_by( value) %>% 
  summarise( min( rate ), max( rate ), range = max(rate) - min(rate)) %>% 
  xc()

df_map  %>% summarise( min( rate ), max( rate ))


df_map %>% 
  filter( rate == 0 ) %>%
  select(lga )  %>%
  inner_join( df_population %>% distinct( lga, lga_name, state_name )) %>%
  arrange( lga ) %>%
  xc()

levels( df_map$value )


hist( df_map$rate)


```
